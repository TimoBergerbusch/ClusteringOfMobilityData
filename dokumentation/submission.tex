% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
%\usepackage{ngerman}
\usepackage[utf8x]{inputenc}
\usepackage{fancyvrb}
\usepackage{courier}
\usepackage{helvet}
\usepackage{tikz}
\usepackage{xcolor}
\usepackage{pdfpages}
\usetikzlibrary{calc}
\usepackage[strict]{changepage}
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{cleveref}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{arrows}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta, automata, shapes, matrix,positioning}
\usepackage{amssymb}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\usepackage{subcaption} 
\usepackage{float}
\usepackage{fixfoot}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{listings}

\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
	%
	\title{Clustering Analysis of Mobility Data}
	%
	%\titlerunning{Abbreviated paper title}
	% If the paper title is too long for the running head, you can set
	% an abbreviated paper title here
	%
	\author{Miriam Wagner\and
		Martin Breuer\and
		Moritz Werthebach\and
		Timo Bergerbusch\and
		Walter Schikowski}
	%
	\authorrunning{F. Author et al.} %TODO
	% First names are abbreviated in the running head.
	% If there are more than two authors, 'et al.' is used.
	%
	\institute{RWTH Aachen, Templergraben 55, 52062 Aachen, Germany}
	%
	\maketitle              % typeset the header of the contribution
	%
	\begin{abstract} %TODO
		The abstract should briefly summarize the contents of the paper in
		150--250 words.
		
		\keywords{Clustering \and Rapidminer \and Cluster \and Data Mining} %TODO: maybe more
	\end{abstract}
	%
	%
	%
	\section{Introduction}
	\section{Preprocessing}\label{sec: proprocessing}
	In order to classify the given data into smaller test sets or mask different aspects, we have to perform analysis.\\
	We observe that even though we have 124979 individual lines defining a movement, there is one line defining a \texttt{NotANumber}-exception and therefore gets neglected for further usage.	\\
	We provide the \texttt{testDataGenerator} python script. Through flags and input arguments the script is able to create all test sets considered by our clustering and neural net approaches.\\
	%TODO: should this be within the paper or more in a ReadMe-file delivered with the script itself?
%	The possible flags and an explanation can be taken from \Cref{fig: testdatagenerator flags}.	
%	\begin{figure}[H]
%		\centering
%		\includegraphics[scale=0.5]{src/pic/testDataGenerator-h.PNG}
%		\caption{The possible arguments to the \texttt{testDataGenerator}}
%		\label{fig: testdatagenerator flags}
%	\end{figure}
	We observe the following distribution over the whole dataset:\\
	{\hspace*{2cm}\setlength\tabcolsep{.2cm}\begin{tabular}{c|ccccccc}
		strata &  1   &   2   &   3   &  4   &  5   &  6   & $\Sigma$ \\ \hline
		 abs   & 6963 & 52265 & 49404 & 8772 & 5536 & 2038 &  124978  \\
		  \%   & 5.57 & 41.82 & 39.53 & 7.02 & 4.43 & 1.63 &   100
	\end{tabular}}\\
	We observe that there is an upper bound on equal distribution through strata 6. It has at most 2038 individual elements.
	
	In addition to the original paper we compute the value \texttt{ID}, which is used to combine movements considered to be from the same person.
	We consider two movements to coincide on the underlying person, if and only if they are consecutive in the original dataset and have the same strata, age and gender.
	{\hspace*{2cm}\setlength\tabcolsep{.2cm}\begin{tabular}{c|ccccccc}
		strata &  1   &   2   &   3   &  4   &  5   &  6  & $\Sigma$ \\ \hline
		 abs   & 3153 & 23367 & 21418 & 3497 & 2083 & 595 &  54113   \\
		  \%   & 5.83 & 43.18 & 39.58 & 6.46 & 3.85 & 1.1 &   100
	\end{tabular}}\\
	So we also have through strata 6 an upper bound of 595 for equally distributed person vector data (see \Cref{subsec: person vector data}).
	
	\subsection{Vector}\label{subsec: person vector data}
	As stated before, instead of simple IDs for every person we expand the parsing by using a data encapsulating in a class called \texttt{Person}. This class stores the ID, the parameters defining a person %TODO: ref zu code basics
	, and all movements from that person.\\
	Then we are able to compute the following vector, with 848 entries, for further usage, that combines all movements of the person:
	\begin{align*}
	\underbrace{\#o_1, \dots, \#o_{413}, \#d_1, \dots, \#d_{413}}_{2\cdot 413} ,
	\underbrace{\mathit{AM}, \mathit{MD}, \mathit{PM}, \mathit{MN}}_{4}, 
	\underbrace{\#r_1, \dots, \#r_7}_{7}, \\
	\underbrace{\#\mathit{MoT}_1, \dots, \#\mathit{MoT}_7}_{7}, \underbrace{\mathit{SDest}, \mathit{SDist}, \mathit{G}, \mathit{A} ,\mathit{strata}, \mathit{strataGrouped}}_{6}
	\end{align*}
	with the following abbreviations ($1 \le i \le 413$, $1 \le j \le 7$):
	\begin{multicols}{2}
		\begin{itemize}
			\setlength{\itemindent}{.4cm}
			\item[$o_i$:]  the $i$-th origin data point
			\item[$d_i$:]  the $i$-th destination data point
			\item[$\mathit{AM}$:] movements at time stamp AM
			\item[$\mathit{MD}$:] movements at time stamp MD
			\item[$\mathit{PM}$:] movements at time stamp PM
			\item[$\mathit{MN}$:] movements at time stamp MN
			\item[$r_j$:] the $j$-th reason
			\item[$\mathit{MoT}_j$:] the $j$-th mean of transportation
			\item[$\mathit{SDest}$:] sum of all durations
			\item[$\mathit{SDist}$:] sum of all distances
			\item[$\mathit{G}$:] the gender
			\item[$\mathit{A}$:] the age
			\item[$strata$:] the strata (used for comparison)
			\item[$strataGrouped$:] the aggregated stratas
		\end{itemize}
	\end{multicols}
	\section{Predicting}
	
	\subsection{Classification}
	\input{MiriamClustering}
	\subsection{Neural Net}
	For all the neural net computations done we considered person vector data sets of different sizes (c.f. \Cref{subsec: person vector data}).\\
	We do this, because results on the normal datasets had an unacceptable performance. An example is given in \Cref{fig: NN without vector}.	
	\begin{figure}
		\centering
		\includegraphics[scale = 0.4]{src/pic/NN_without_vector.png}
		\caption{An example of a neural net trained without person vector data.}
		\label{fig: NN without vector}
	\end{figure}
	
	In the following we consider 3 neural nets $\mathcal{N}_1,\mathcal{N}_2$ and $\mathcal{N}_3$, all having 4 hidden layers, 50 epochs and 10 iterations.	
	As an example of other strata aggregation we combine the stratas 1--2, 3--4 and 5--6 together and call them $\mathcal{N}_i^\star$, for $i \in \{5,10,20\}$. This builds a superset of the original stratas and since the stratas themselves are logically connected this task should be easier to fulfill.\\
	The sets are provided by the \texttt{testDataGenerator} from \Cref{sec: proprocessing}.
	\setlength\tabcolsep{.2cm}
	\begin{figure}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|c|}
		\hline
		                         &   \#    &        & \multicolumn{3}{c|}{Set size} \\
		          Name           & Neurons &   AG   &  100  &  200  &      595      \\ \hline
		    $\mathcal{N}_5$      &    5    & \xmark & 60.03 & 59.92 &     60.18     \\
		 $\mathcal{N}_5^\star$   &    5    & \cmark & 87.6  & 89.7  &     71.05     \\
		   $\mathcal{N}_{10}$    &   10    & \xmark & 75.83 & 73.54 &     69.56     \\
		$\mathcal{N}_{10}^\star$ &   10    & \cmark & 92.93 & 93.48 &     74.58     \\		
		%		$\mathcal{N}_{10}^\star$ &   10    & \cmark & 88.33 {\small $\pm$7.49} & 90.67{\small $\pm$2.81} & 92.14 {\small $\pm$ 2.59} \\
		   $\mathcal{N}_{20}$    &   20    & \xmark & 75.45 & 71.14 &     61.87     \\
		$\mathcal{N}_{20}^\star$ &   20    & \cmark & 92.87 & 94.4  &     78.32     \\ \hline
	\end{tabular}
	\caption{The accuracy values of the neural nets. (See excel-spreadsheet)}
	\label{tab: nn-accuracy}
	% mittels deep-learning-vector-average
	\end{figure}

	For each we performed 5 independent runs and take an average over those accuracy values in order to have a sophisticated statement.\\


	The size of larger nets in terms of neurons is counter-productive, since if we take 50 neurons per layer we have $14 \cdot 50^4 \cdot 6 \approxeq 525.000.000$ synapses for which the input data set would be to small to have sufficient training.\\

	%TODO: what can we oberve?
%	The greater the population, the more the borders between the stratas blur. 



\end{document}
